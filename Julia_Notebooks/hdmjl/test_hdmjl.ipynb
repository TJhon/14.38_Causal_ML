{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "92162901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant packages for splitting data\n",
    "using LinearAlgebra, GLM, DataFrames, Statistics, Random, Distributions, Tables, TableOperations, StatsBase, FreqTables, DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8bf7bd44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cvec (generic function with 1 method)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a function which turn a list or vector-like object into a proper two\n",
    "# dimensional column vector\n",
    "\n",
    "function cvec(a)\n",
    "    \"\"\" Turn a list or vector-like object into a proper column vector\n",
    "    Input\n",
    "    a: List or vector-like object, has to be a potential input for np.array()\n",
    "    Output\n",
    "    vec: two dimensional NumPy array, with the first dimension weakly greater\n",
    "         than the second (resulting in a column vector for a vector-like input)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Conver input into a two dimensional NumPy array\n",
    "    vec = cat([a], dims = 2) \n",
    "\n",
    "    # Check whether the second dimension is strictly greater than the first\n",
    "    # (remembering Python's zero indexing)\n",
    "    \n",
    "    if size(vec)[1] < size(vec)[2]\n",
    "        # If so, transpose the input vector\n",
    "        vec = transpose(vec)\n",
    "    end\n",
    "   \n",
    "    # Return the column vector\n",
    "    return vec\n",
    "\n",
    "end\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cd830368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "corre (generic function with 1 method)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import Statistics.cor\n",
    "function corre(y, X)\n",
    "    \n",
    "    \"\"\" Return correlation coefficients between columns of matrices\n",
    "    Inputs\n",
    "    y: n by 1 NumPy array\n",
    "    X: n by k NumPy array\n",
    "    Outputs\n",
    "    corr: list of length k, where the k-th element is the correlation\n",
    "          coefficient between y and the k-th column of X\n",
    "    \"\"\"\n",
    "    # Concatenate y and X into a single NumPy array\n",
    "    yX = hcat(y, X)\n",
    "    \n",
    "    # Get the correlation coefficients between all columns of that array\n",
    "    corr = cor(yX)\n",
    "    \n",
    "    # Get the first row, starting at the first off-diagonal element (these are\n",
    "    # the correlation coefficients between y and each column of X\n",
    "    corr = corr[1, :] \n",
    "    \n",
    "    # Return the result\n",
    "    return corr\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cb4657a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "init_values (generic function with 3 methods)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function init_values(X, y, number::Int64=5, intercetp::Bool=true)\n",
    "    \"\"\" Return an initial parameter guess for a LASSO model\n",
    "    Inputs\n",
    "    y: n by 1 NumPy array, outcome variable\n",
    "    X: n by k NumPy array, RHS variables\n",
    "    Outputs\n",
    "    residuals: n ny 1 NumPy array, residuals for initial parameter guess\n",
    "    coefficients: k by 1 NumPy array, initial coefficient values\n",
    "    \"\"\"\n",
    "    # Make sure y is a proper column vector\n",
    "    #y = cvec(y)\n",
    "    \n",
    "    # Get the absolute value of correlations between y and X\n",
    "    corr = broadcast(abs, cor(y, X)[1, :])\n",
    "    \n",
    "    # Get the number of columns of X\n",
    "    kx = size(X)[2]\n",
    "    \n",
    "    # Make an index selecting the five columns of X which are most correlated\n",
    "    # with y (since .argsort() always sorts in increasing order, selecting from\n",
    "    # the back gets the most highly correlated columns)\n",
    "    index = sortperm(corr, rev=true)[1: min(number, kx)]\n",
    "    \n",
    "    # Set up an array of coefficient guesses\n",
    "    coefficients = zeros(kx)\n",
    "    \n",
    "    # Regress y on the five most correlated columns of X, including an intercept\n",
    "    # if desired\n",
    "#    reg = lm(X[:, index], y)\n",
    "    \n",
    "#     # Replace the guesses for the estimated coefficients (note that .coef_ does\n",
    "#     # not return the estimated intercept, if one was included in the model)\n",
    "    \n",
    "#     coefficients[index] = GLM.coef(reg)\n",
    "    \n",
    "#     # Replace any NANs as zeros\n",
    "#     replace!(coefficients, NaN=>0)\n",
    "    \n",
    "#     # Get the regression residuals\n",
    "#     residuals = y - predict(reg, X[:, index])\n",
    "    \n",
    "#     return residuals, reg, index, coefficients, corr\n",
    "    return index\n",
    "    \n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "66b7e664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function LassoShooting_fit( x, y, lmbda, maxIter::Int = 1000, optTol::Float64 = 10^(-5), zeroThreshold::Float64 = 10^(-6),\n",
    "#                             XX = nothing, Xy = nothing, beta_start = nothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "70384342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LassoShooting_fit (generic function with 7 methods)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function LassoShooting_fit( x, y, lmbda, control::control, \n",
    "#                             XX = nothing, Xy = nothing, beta_start = nothing)\n",
    "\n",
    "function LassoShooting_fit( x, y, lmbda, maxIter::Int = 1000, optTol::Float64 = 10^(-5), zeroThreshold::Float64 = 10^(-6),\n",
    "                            XX = nothing, Xy = nothing, beta_start = nothing)\n",
    "        \n",
    "     \"\"\" Shooting LASSO algorithm with variable dependent penalty weights\n",
    "    Inputs\n",
    "    x: n by p NumPy array, RHS variables\n",
    "    y: n by 1 NumPy array, outcome variable\n",
    "    lmbda: p by 1 NumPy array, variable dependent penalty terms. The j-th\n",
    "           element is the penalty term for the j-th RHS variable.\n",
    "    maxIter: integer, maximum number of shooting LASSO updated\n",
    "    optTol: scalar, algorithm terminated once the sum of absolute differences\n",
    "            between the updated and current weights is below optTol\n",
    "    zeroThreshold: scalar, if any final weights are below zeroThreshold, they\n",
    "                   will be set to zero instead\n",
    "    XX: k by k NumPy array, pre-calculated version of x'x\n",
    "    Xy: k by 1 NumPy array, pre-calculated version of x'y\n",
    "    beta_start: k by 1 NumPy array, initial weights\n",
    "    Outputs\n",
    "    w: k by 1 NumPy array, final weights\n",
    "    wp: k by m + 1 NumPy array, where m is the number of iterations the\n",
    "        algorithm took. History of weight updates, starting with the initial\n",
    "        weights.\n",
    "    m: integer, number of iterations the algorithm took\n",
    "    \"\"\"\n",
    "    n = size(x)[1]\n",
    "    p = size(x)[2]\n",
    "    \n",
    "    # Check whether XX and Xy were provided, calculate them if not\n",
    "    if (isnothing(XX))\n",
    "        XX = x'*x\n",
    "    end\n",
    "\n",
    "    if (isnothing(Xy))\n",
    "        Xy = x'*y\n",
    "    end\n",
    "\n",
    "    # Check whether an initial value for the intercept was provided\n",
    "\n",
    "    if (isnothing(beta_start))\n",
    "        # If not, use init_values from help_functions, which will return\n",
    "        # regression estimates for the five variables in x which are most\n",
    "        # correlated with y, and initialize all other coefficients as zero\n",
    "        beta = init_values(x, y)[4]\n",
    "\n",
    "    else\n",
    "        # Otherwise, use the provided initial weights\n",
    "        beta = beta_start\n",
    "    end\n",
    "\n",
    "    # Set up a history of weights over time, starting with the initial ones\n",
    "    wp = beta\n",
    "\n",
    "    # Keep track of the number of iterations\n",
    "    m = 1\n",
    "\n",
    "    # Create versions of XX and Xy which are just those matrices times two\n",
    "    XX2 = XX * 2\n",
    "    Xy2 = Xy * 2\n",
    "\n",
    "    #@unpack maxIter, optTol, zeroThreshold = control()\n",
    "\n",
    "    # Go through all iteration\n",
    "    while m<maxIter\n",
    "\n",
    "        # Save the last set of weights (the .copy() is important, otherwise\n",
    "        # beta_old will be updated every time beta is changed during the\n",
    "        # following loop)\n",
    "        beta_old = copy(beta)\n",
    "\n",
    "        # Go through all parameters\n",
    "        for j in 1:p\n",
    "            \n",
    "            # Calculate the shoot\n",
    "            S0 = sum( XX2[j, :].*beta ) - XX2[j, j].*beta[j] - Xy2[j]\n",
    "\n",
    "            # Update the weights\n",
    "            if sum(isnothing(XX)) >= 1\n",
    "                beta[j] = 0\n",
    "\n",
    "            elseif S0 >lmbda[j]\n",
    "                beta[j] = (lmbda[j] - S0) / XX2[j,j]\n",
    "\n",
    "            elseif S0 < -lmbda[j]\n",
    "                beta[j] = (-lmbda[j] - S0) / XX2[j,j]\n",
    "\n",
    "            elseif broadcast(abs, S0) <= lmbda[j]\n",
    "                beta[j] = 0\n",
    "\n",
    "            end\n",
    "        end\n",
    "\n",
    "        # Add the updated weights to the history of weights\n",
    "        wp = hcat(wp, beta)\n",
    "\n",
    "        # Check whether the weights are within tolerance\n",
    "        if sum(broadcast(abs, beta - beta_old)) < optTol\n",
    "            # If so, break the while loop\n",
    "            break\n",
    "        end\n",
    "\n",
    "        # Increase the iteration counter\n",
    "        m = m + 1\n",
    "    end\n",
    "\n",
    "    # Set the final weights to the last updated weights\n",
    "    w = beta   \n",
    "\n",
    "    # Set weights which are within zeroThreshold to zero\n",
    "    w[broadcast(abs, w) .< zeroThreshold] .= 0\n",
    "    \n",
    "    #return beta,  w\n",
    "    return Dict(\"coefficients\" => w, \"coef_list\" => wp, \"num_it\" => m)\n",
    "    return w, wp, m\n",
    "    #return XX2, Xy2\n",
    "    \n",
    "\n",
    "end\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0db3cacc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Vector{Float64}:\n",
       "  0.9390236880834457\n",
       "  1.062875086192527\n",
       "  0.5817862916124238\n",
       " -0.09281756897873912\n",
       "  0.2546410204259804\n",
       "  0.9994262690418787\n",
       "  0.5914104665434333\n",
       "  0.9514550733700607\n",
       " -0.3828570823089012\n",
       "  0.3774992183051544"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We have to make sure that both variables are the same type (Integers or floats) to avoid errors when running the regression\n",
    "n = 10\n",
    "p = Int(n/2)\n",
    "\n",
    "X = randn(n, p)\n",
    "beta = randn(p)\n",
    "lmbda = randn(p)\n",
    "Y = randn(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d75d93e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearModel{GLM.LmResp{Vector{Float64}}, GLM.DensePredChol{Float64, CholeskyPivoted{Float64, Matrix{Float64}}}}:\n",
       "\n",
       "Coefficients:\n",
       "─────────────────────────────────────────────────────────────────\n",
       "         Coef.  Std. Error      t  Pr(>|t|)  Lower 95%  Upper 95%\n",
       "─────────────────────────────────────────────────────────────────\n",
       "x1  -0.443655     0.259419  -1.71    0.1479  -1.11051    0.223204\n",
       "x2  -0.0201311    0.225097  -0.09    0.9322  -0.598762   0.5585\n",
       "x3   0.0879272    0.207484   0.42    0.6893  -0.445427   0.621282\n",
       "x4   0.121388     0.303989   0.40    0.7061  -0.660041   0.902818\n",
       "x5   0.112992     0.298344   0.38    0.7204  -0.653925   0.879908\n",
       "─────────────────────────────────────────────────────────────────\n"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4ef48636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Vector{Int64}:\n",
       " 3\n",
       " 1\n",
       " 2\n",
       " 4\n",
       " 5"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_values(X, Y)\n",
    "#LassoShooting_fit(X, Y, lmbda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7dc1f8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "using RData, LinearAlgebra, GLM, DataFrames, Statistics, Random, Distributions, DataStructures, NamedArrays, PrettyTables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5f8cf742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>90 rows × 62 columns (omitted printing of 53 columns)</p><table class=\"data-frame\"><thead><tr><th></th><th>intercept</th><th>gdpsh465</th><th>bmp1l</th><th>freeop</th><th>freetar</th><th>h65</th><th>hm65</th><th>hf65</th><th>p65</th></tr><tr><th></th><th title=\"Int32\">Int32</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th></tr></thead><tbody><tr><th>1</th><td>1</td><td>6.59167</td><td>0.2837</td><td>0.153491</td><td>0.043888</td><td>0.007</td><td>0.013</td><td>0.001</td><td>0.29</td></tr><tr><th>2</th><td>1</td><td>6.82979</td><td>0.6141</td><td>0.313509</td><td>0.061827</td><td>0.019</td><td>0.032</td><td>0.007</td><td>0.91</td></tr><tr><th>3</th><td>1</td><td>8.89508</td><td>0.0</td><td>0.204244</td><td>0.009186</td><td>0.26</td><td>0.325</td><td>0.201</td><td>1.0</td></tr><tr><th>4</th><td>1</td><td>7.56528</td><td>0.1997</td><td>0.248714</td><td>0.03627</td><td>0.061</td><td>0.07</td><td>0.051</td><td>1.0</td></tr><tr><th>5</th><td>1</td><td>7.1624</td><td>0.174</td><td>0.299252</td><td>0.037367</td><td>0.017</td><td>0.027</td><td>0.007</td><td>0.82</td></tr><tr><th>6</th><td>1</td><td>7.21891</td><td>0.0</td><td>0.258865</td><td>0.02088</td><td>0.023</td><td>0.038</td><td>0.006</td><td>0.5</td></tr><tr><th>7</th><td>1</td><td>7.8536</td><td>0.0</td><td>0.182525</td><td>0.014385</td><td>0.039</td><td>0.063</td><td>0.014</td><td>0.92</td></tr><tr><th>8</th><td>1</td><td>7.70391</td><td>0.2776</td><td>0.215275</td><td>0.029713</td><td>0.024</td><td>0.035</td><td>0.013</td><td>0.69</td></tr><tr><th>9</th><td>1</td><td>9.06346</td><td>0.0</td><td>0.109614</td><td>0.002171</td><td>0.402</td><td>0.488</td><td>0.314</td><td>1.0</td></tr><tr><th>10</th><td>1</td><td>8.15191</td><td>0.1484</td><td>0.110885</td><td>0.028579</td><td>0.145</td><td>0.173</td><td>0.114</td><td>1.0</td></tr><tr><th>11</th><td>1</td><td>6.92952</td><td>0.0296</td><td>0.165784</td><td>0.020115</td><td>0.046</td><td>0.066</td><td>0.025</td><td>0.73</td></tr><tr><th>12</th><td>1</td><td>7.23778</td><td>0.2151</td><td>0.078488</td><td>0.011581</td><td>0.022</td><td>0.031</td><td>0.014</td><td>1.0</td></tr><tr><th>13</th><td>1</td><td>8.11582</td><td>0.4318</td><td>0.137482</td><td>0.026547</td><td>0.059</td><td>0.073</td><td>0.045</td><td>1.0</td></tr><tr><th>14</th><td>1</td><td>7.2717</td><td>0.1689</td><td>0.164598</td><td>0.044446</td><td>0.029</td><td>0.045</td><td>0.013</td><td>0.84</td></tr><tr><th>15</th><td>1</td><td>7.12125</td><td>0.1832</td><td>0.188016</td><td>0.045678</td><td>0.033</td><td>0.051</td><td>0.015</td><td>0.91</td></tr><tr><th>16</th><td>1</td><td>6.97728</td><td>0.0962</td><td>0.204611</td><td>0.077852</td><td>0.037</td><td>0.043</td><td>0.03</td><td>1.0</td></tr><tr><th>17</th><td>1</td><td>7.64969</td><td>0.0227</td><td>0.136287</td><td>0.04673</td><td>0.081</td><td>0.105</td><td>0.056</td><td>0.99</td></tr><tr><th>18</th><td>1</td><td>8.05674</td><td>0.0208</td><td>0.197853</td><td>0.037224</td><td>0.083</td><td>0.097</td><td>0.069</td><td>1.0</td></tr><tr><th>19</th><td>1</td><td>8.78094</td><td>0.2654</td><td>0.189867</td><td>0.031747</td><td>0.068</td><td>0.089</td><td>0.046</td><td>0.94</td></tr><tr><th>20</th><td>1</td><td>6.28786</td><td>0.4207</td><td>0.130682</td><td>0.109921</td><td>0.053</td><td>0.039</td><td>0.011</td><td>0.74</td></tr><tr><th>21</th><td>1</td><td>6.13773</td><td>0.1371</td><td>0.123818</td><td>0.015897</td><td>0.028</td><td>0.025</td><td>0.007</td><td>0.72</td></tr><tr><th>22</th><td>1</td><td>8.12888</td><td>0.0</td><td>0.16721</td><td>0.003311</td><td>0.129</td><td>0.196</td><td>0.063</td><td>1.0</td></tr><tr><th>23</th><td>1</td><td>6.68085</td><td>0.4713</td><td>0.228424</td><td>0.029328</td><td>0.062</td><td>0.09</td><td>0.032</td><td>1.0</td></tr><tr><th>24</th><td>1</td><td>7.17702</td><td>0.0178</td><td>0.18524</td><td>0.015453</td><td>0.02</td><td>0.026</td><td>0.013</td><td>0.9</td></tr><tr><th>25</th><td>1</td><td>6.64898</td><td>0.4762</td><td>0.171181</td><td>0.058937</td><td>0.018</td><td>0.028</td><td>0.007</td><td>0.4</td></tr><tr><th>26</th><td>1</td><td>6.87936</td><td>0.2927</td><td>0.179508</td><td>0.035842</td><td>0.188</td><td>0.169</td><td>0.208</td><td>1.0</td></tr><tr><th>27</th><td>1</td><td>7.3473</td><td>0.1017</td><td>0.247626</td><td>0.037392</td><td>0.08</td><td>0.133</td><td>0.027</td><td>0.78</td></tr><tr><th>28</th><td>1</td><td>6.72503</td><td>0.0266</td><td>0.179933</td><td>0.046376</td><td>0.015</td><td>0.02</td><td>0.01</td><td>0.78</td></tr><tr><th>29</th><td>1</td><td>8.45105</td><td>0.0</td><td>0.358556</td><td>0.016468</td><td>0.09</td><td>0.133</td><td>0.044</td><td>1.0</td></tr><tr><th>30</th><td>1</td><td>8.60245</td><td>0.0</td><td>0.416234</td><td>0.014721</td><td>0.148</td><td>0.194</td><td>0.1</td><td>1.0</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccccccc}\n",
       "\t& intercept & gdpsh465 & bmp1l & freeop & freetar & h65 & hm65 & hf65 & p65 & \\\\\n",
       "\t\\hline\n",
       "\t& Int32 & Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & \\\\\n",
       "\t\\hline\n",
       "\t1 & 1 & 6.59167 & 0.2837 & 0.153491 & 0.043888 & 0.007 & 0.013 & 0.001 & 0.29 & $\\dots$ \\\\\n",
       "\t2 & 1 & 6.82979 & 0.6141 & 0.313509 & 0.061827 & 0.019 & 0.032 & 0.007 & 0.91 & $\\dots$ \\\\\n",
       "\t3 & 1 & 8.89508 & 0.0 & 0.204244 & 0.009186 & 0.26 & 0.325 & 0.201 & 1.0 & $\\dots$ \\\\\n",
       "\t4 & 1 & 7.56528 & 0.1997 & 0.248714 & 0.03627 & 0.061 & 0.07 & 0.051 & 1.0 & $\\dots$ \\\\\n",
       "\t5 & 1 & 7.1624 & 0.174 & 0.299252 & 0.037367 & 0.017 & 0.027 & 0.007 & 0.82 & $\\dots$ \\\\\n",
       "\t6 & 1 & 7.21891 & 0.0 & 0.258865 & 0.02088 & 0.023 & 0.038 & 0.006 & 0.5 & $\\dots$ \\\\\n",
       "\t7 & 1 & 7.8536 & 0.0 & 0.182525 & 0.014385 & 0.039 & 0.063 & 0.014 & 0.92 & $\\dots$ \\\\\n",
       "\t8 & 1 & 7.70391 & 0.2776 & 0.215275 & 0.029713 & 0.024 & 0.035 & 0.013 & 0.69 & $\\dots$ \\\\\n",
       "\t9 & 1 & 9.06346 & 0.0 & 0.109614 & 0.002171 & 0.402 & 0.488 & 0.314 & 1.0 & $\\dots$ \\\\\n",
       "\t10 & 1 & 8.15191 & 0.1484 & 0.110885 & 0.028579 & 0.145 & 0.173 & 0.114 & 1.0 & $\\dots$ \\\\\n",
       "\t11 & 1 & 6.92952 & 0.0296 & 0.165784 & 0.020115 & 0.046 & 0.066 & 0.025 & 0.73 & $\\dots$ \\\\\n",
       "\t12 & 1 & 7.23778 & 0.2151 & 0.078488 & 0.011581 & 0.022 & 0.031 & 0.014 & 1.0 & $\\dots$ \\\\\n",
       "\t13 & 1 & 8.11582 & 0.4318 & 0.137482 & 0.026547 & 0.059 & 0.073 & 0.045 & 1.0 & $\\dots$ \\\\\n",
       "\t14 & 1 & 7.2717 & 0.1689 & 0.164598 & 0.044446 & 0.029 & 0.045 & 0.013 & 0.84 & $\\dots$ \\\\\n",
       "\t15 & 1 & 7.12125 & 0.1832 & 0.188016 & 0.045678 & 0.033 & 0.051 & 0.015 & 0.91 & $\\dots$ \\\\\n",
       "\t16 & 1 & 6.97728 & 0.0962 & 0.204611 & 0.077852 & 0.037 & 0.043 & 0.03 & 1.0 & $\\dots$ \\\\\n",
       "\t17 & 1 & 7.64969 & 0.0227 & 0.136287 & 0.04673 & 0.081 & 0.105 & 0.056 & 0.99 & $\\dots$ \\\\\n",
       "\t18 & 1 & 8.05674 & 0.0208 & 0.197853 & 0.037224 & 0.083 & 0.097 & 0.069 & 1.0 & $\\dots$ \\\\\n",
       "\t19 & 1 & 8.78094 & 0.2654 & 0.189867 & 0.031747 & 0.068 & 0.089 & 0.046 & 0.94 & $\\dots$ \\\\\n",
       "\t20 & 1 & 6.28786 & 0.4207 & 0.130682 & 0.109921 & 0.053 & 0.039 & 0.011 & 0.74 & $\\dots$ \\\\\n",
       "\t21 & 1 & 6.13773 & 0.1371 & 0.123818 & 0.015897 & 0.028 & 0.025 & 0.007 & 0.72 & $\\dots$ \\\\\n",
       "\t22 & 1 & 8.12888 & 0.0 & 0.16721 & 0.003311 & 0.129 & 0.196 & 0.063 & 1.0 & $\\dots$ \\\\\n",
       "\t23 & 1 & 6.68085 & 0.4713 & 0.228424 & 0.029328 & 0.062 & 0.09 & 0.032 & 1.0 & $\\dots$ \\\\\n",
       "\t24 & 1 & 7.17702 & 0.0178 & 0.18524 & 0.015453 & 0.02 & 0.026 & 0.013 & 0.9 & $\\dots$ \\\\\n",
       "\t25 & 1 & 6.64898 & 0.4762 & 0.171181 & 0.058937 & 0.018 & 0.028 & 0.007 & 0.4 & $\\dots$ \\\\\n",
       "\t26 & 1 & 6.87936 & 0.2927 & 0.179508 & 0.035842 & 0.188 & 0.169 & 0.208 & 1.0 & $\\dots$ \\\\\n",
       "\t27 & 1 & 7.3473 & 0.1017 & 0.247626 & 0.037392 & 0.08 & 0.133 & 0.027 & 0.78 & $\\dots$ \\\\\n",
       "\t28 & 1 & 6.72503 & 0.0266 & 0.179933 & 0.046376 & 0.015 & 0.02 & 0.01 & 0.78 & $\\dots$ \\\\\n",
       "\t29 & 1 & 8.45105 & 0.0 & 0.358556 & 0.016468 & 0.09 & 0.133 & 0.044 & 1.0 & $\\dots$ \\\\\n",
       "\t30 & 1 & 8.60245 & 0.0 & 0.416234 & 0.014721 & 0.148 & 0.194 & 0.1 & 1.0 & $\\dots$ \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m90×62 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m intercept \u001b[0m\u001b[1m gdpsh465 \u001b[0m\u001b[1m bmp1l   \u001b[0m\u001b[1m freeop   \u001b[0m\u001b[1m freetar  \u001b[0m\u001b[1m h65     \u001b[0m\u001b[1m hm65    \u001b[0m\u001b[1m hf6\u001b[0m ⋯\n",
       "\u001b[1m     \u001b[0m│\u001b[90m Int32     \u001b[0m\u001b[90m Float64  \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64  \u001b[0m\u001b[90m Float64  \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Flo\u001b[0m ⋯\n",
       "─────┼──────────────────────────────────────────────────────────────────────────\n",
       "   1 │         1   6.59167   0.2837  0.153491  0.043888    0.007    0.013    0 ⋯\n",
       "   2 │         1   6.82979   0.6141  0.313509  0.061827    0.019    0.032    0\n",
       "   3 │         1   8.89508   0.0     0.204244  0.009186    0.26     0.325    0\n",
       "   4 │         1   7.56528   0.1997  0.248714  0.03627     0.061    0.07     0\n",
       "   5 │         1   7.1624    0.174   0.299252  0.037367    0.017    0.027    0 ⋯\n",
       "   6 │         1   7.21891   0.0     0.258865  0.02088     0.023    0.038    0\n",
       "   7 │         1   7.8536    0.0     0.182525  0.014385    0.039    0.063    0\n",
       "   8 │         1   7.70391   0.2776  0.215275  0.029713    0.024    0.035    0\n",
       "   9 │         1   9.06346   0.0     0.109614  0.002171    0.402    0.488    0 ⋯\n",
       "  10 │         1   8.15191   0.1484  0.110885  0.028579    0.145    0.173    0\n",
       "  11 │         1   6.92952   0.0296  0.165784  0.020115    0.046    0.066    0\n",
       "  ⋮  │     ⋮         ⋮         ⋮        ⋮         ⋮         ⋮        ⋮         ⋱\n",
       "  81 │         1   9.03097   0.0     0.293138  0.005517    0.245    0.251    0\n",
       "  82 │         1   8.99554   0.0     0.30472   0.011658    0.246    0.26     0 ⋯\n",
       "  83 │         1   8.23483   0.0363  0.288405  0.011589    0.183    0.222    0\n",
       "  84 │         1   8.33255   0.0     0.345485  0.006503    0.188    0.248    0\n",
       "  85 │         1   8.64559   0.0     0.28844   0.005995    0.256    0.301    0\n",
       "  86 │         1   8.99106   0.0     0.371898  0.014586    0.255    0.336    0 ⋯\n",
       "  87 │         1   8.02519   0.005   0.296437  0.013615    0.108    0.117    0\n",
       "  88 │         1   9.03014   0.0     0.265778  0.008629    0.288    0.337    0\n",
       "  89 │         1   8.86531   0.0     0.282939  0.005048    0.188    0.236    0\n",
       "  90 │         1   8.91234   0.0     0.150366  0.024377    0.257    0.338    0 ⋯\n",
       "\u001b[36m                                                  55 columns and 69 rows omitted\u001b[0m"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing .Rdata file\n",
    "growth_read = load(\"../../data/GrowthData.RData\")\n",
    "\n",
    "# Since growth_read is a dictionary, we check if there is a key called \"GrowthData\", the one we need for our analyze\n",
    "haskey(growth_read, \"GrowthData\")\n",
    "# Now we save that dataframe with a new name\n",
    "growth = growth_read[\"GrowthData\"]\n",
    "names(growth)\n",
    "\n",
    "Y = growth[!, \"Outcome\"]\n",
    "Y_2 = DataFrame([Y], [:Y])\n",
    "X_2 = select(growth, Not([\"Outcome\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0cf66868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Vector{Float64}:\n",
       " -1.3201593173151316\n",
       "  0.48202075083438606\n",
       " -0.28271178764718186\n",
       " -0.7896844104717727"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_2 = convert(Matrix, Matrix(X_2[:, 2:5]))\n",
    "Y_2 = convert(Matrix, Matrix(Y_2))\n",
    "lmbda = randn(size(X_2)[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0c85d139",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "MethodError: no method matching fit(::Type{LinearModel}, ::Matrix{Float64}, ::Matrix{Float64}, ::Nothing)\n\u001b[0mClosest candidates are:\n\u001b[0m  fit(::Type{LinearModel}, ::AbstractMatrix{<:Real}, \u001b[91m::AbstractVector{<:Real}\u001b[39m, ::Union{Nothing, Bool}; wts, dropcollinear) at C:\\Users\\Alexander\\.julia\\packages\\GLM\\gt3bb\\src\\lm.jl:161\n\u001b[0m  fit(\u001b[91m::Type{Histogram}\u001b[39m, ::Any...; kwargs...) at C:\\Users\\Alexander\\.julia\\packages\\StatsBase\\pJqvO\\src\\hist.jl:383\n\u001b[0m  fit(::Type{T}, \u001b[91m::FormulaTerm\u001b[39m, ::Any, ::Any...; contrasts, kwargs...) where T<:RegressionModel at C:\\Users\\Alexander\\.julia\\packages\\StatsModels\\57Kc9\\src\\statsmodel.jl:78\n\u001b[0m  ...",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching fit(::Type{LinearModel}, ::Matrix{Float64}, ::Matrix{Float64}, ::Nothing)\n\u001b[0mClosest candidates are:\n\u001b[0m  fit(::Type{LinearModel}, ::AbstractMatrix{<:Real}, \u001b[91m::AbstractVector{<:Real}\u001b[39m, ::Union{Nothing, Bool}; wts, dropcollinear) at C:\\Users\\Alexander\\.julia\\packages\\GLM\\gt3bb\\src\\lm.jl:161\n\u001b[0m  fit(\u001b[91m::Type{Histogram}\u001b[39m, ::Any...; kwargs...) at C:\\Users\\Alexander\\.julia\\packages\\StatsBase\\pJqvO\\src\\hist.jl:383\n\u001b[0m  fit(::Type{T}, \u001b[91m::FormulaTerm\u001b[39m, ::Any, ::Any...; contrasts, kwargs...) where T<:RegressionModel at C:\\Users\\Alexander\\.julia\\packages\\StatsModels\\57Kc9\\src\\statsmodel.jl:78\n\u001b[0m  ...",
      "",
      "Stacktrace:",
      " [1] lm(X::Matrix{Float64}, y::Matrix{Float64}, allowrankdeficient_dep::Nothing; kwargs::Base.Pairs{Symbol, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})",
      "   @ GLM C:\\Users\\Alexander\\.julia\\packages\\GLM\\gt3bb\\src\\lm.jl:184",
      " [2] lm(X::Matrix{Float64}, y::Matrix{Float64}, allowrankdeficient_dep::Nothing) (repeats 2 times)",
      "   @ GLM C:\\Users\\Alexander\\.julia\\packages\\GLM\\gt3bb\\src\\lm.jl:184",
      " [3] top-level scope",
      "   @ In[63]:1",
      " [4] eval",
      "   @ .\\boot.jl:373 [inlined]",
      " [5] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base .\\loading.jl:1196"
     ]
    }
   ],
   "source": [
    "lm(X_2, Y_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f4e02fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Pkg\n",
    "# Pkg.add(\"CSV\")\n",
    "# Pkg.add(\"DataFrames\")\n",
    "# Pkg.add(\"Dates\")\n",
    "# Pkg.add(\"Plots\")\n",
    "using CSV\n",
    "using DataFrames\n",
    "using Dates\n",
    "#using Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fae15314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Rows : 5150\n",
      "Number of Columns : 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>5,150 rows × 18 columns (omitted printing of 9 columns)</p><table class=\"data-frame\"><thead><tr><th></th><th>sex</th><th>shs</th><th>hsg</th><th>scl</th><th>clg</th><th>ad</th><th>mw</th><th>so</th><th>we</th></tr><tr><th></th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th></tr></thead><tbody><tr><th>1</th><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>2</th><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>3</th><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>4</th><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>5</th><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>6</th><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>7</th><td>1.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>8</th><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>9</th><td>1.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>10</th><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>11</th><td>1.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>12</th><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>13</th><td>1.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>14</th><td>1.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>15</th><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>16</th><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>17</th><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>18</th><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>19</th><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>20</th><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>21</th><td>1.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>22</th><td>1.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>23</th><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>24</th><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>25</th><td>1.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>26</th><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>27</th><td>1.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>28</th><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>29</th><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>30</th><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccccccc}\n",
       "\t& sex & shs & hsg & scl & clg & ad & mw & so & we & \\\\\n",
       "\t\\hline\n",
       "\t& Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & \\\\\n",
       "\t\\hline\n",
       "\t1 & 1.0 & 0.0 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t2 & 0.0 & 0.0 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t3 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t4 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t5 & 1.0 & 0.0 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t6 & 1.0 & 0.0 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t7 & 1.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t8 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t9 & 1.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t10 & 1.0 & 0.0 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t11 & 1.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t12 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t13 & 1.0 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t14 & 1.0 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t15 & 1.0 & 0.0 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t16 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t17 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t18 & 0.0 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t19 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t20 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t21 & 1.0 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t22 & 1.0 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t23 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t24 & 0.0 & 0.0 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t25 & 1.0 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t26 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t27 & 1.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t28 & 0.0 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t29 & 0.0 & 0.0 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t30 & 0.0 & 0.0 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m5150×18 DataFrame\u001b[0m\n",
       "\u001b[1m  Row \u001b[0m│\u001b[1m sex     \u001b[0m\u001b[1m shs     \u001b[0m\u001b[1m hsg     \u001b[0m\u001b[1m scl     \u001b[0m\u001b[1m clg     \u001b[0m\u001b[1m ad      \u001b[0m\u001b[1m mw      \u001b[0m\u001b[1m so     \u001b[0m ⋯\n",
       "\u001b[1m      \u001b[0m│\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64\u001b[0m ⋯\n",
       "──────┼─────────────────────────────────────────────────────────────────────────\n",
       "    1 │     1.0      0.0      0.0      0.0      1.0      0.0      0.0      0.0 ⋯\n",
       "    2 │     0.0      0.0      0.0      0.0      1.0      0.0      0.0      0.0\n",
       "    3 │     0.0      0.0      1.0      0.0      0.0      0.0      0.0      0.0\n",
       "    4 │     1.0      0.0      0.0      0.0      0.0      1.0      0.0      0.0\n",
       "    5 │     1.0      0.0      0.0      0.0      1.0      0.0      0.0      0.0 ⋯\n",
       "    6 │     1.0      0.0      0.0      0.0      1.0      0.0      0.0      0.0\n",
       "    7 │     1.0      0.0      1.0      0.0      0.0      0.0      0.0      0.0\n",
       "    8 │     0.0      0.0      1.0      0.0      0.0      0.0      0.0      0.0\n",
       "    9 │     1.0      0.0      1.0      0.0      0.0      0.0      0.0      0.0 ⋯\n",
       "   10 │     1.0      0.0      0.0      0.0      1.0      0.0      0.0      0.0\n",
       "   11 │     1.0      0.0      1.0      0.0      0.0      0.0      0.0      0.0\n",
       "  ⋮   │    ⋮        ⋮        ⋮        ⋮        ⋮        ⋮        ⋮        ⋮    ⋱\n",
       " 5141 │     1.0      0.0      0.0      0.0      1.0      0.0      0.0      0.0\n",
       " 5142 │     0.0      0.0      1.0      0.0      0.0      0.0      0.0      0.0 ⋯\n",
       " 5143 │     0.0      0.0      1.0      0.0      0.0      0.0      0.0      0.0\n",
       " 5144 │     1.0      0.0      0.0      0.0      1.0      0.0      0.0      0.0\n",
       " 5145 │     0.0      0.0      0.0      0.0      1.0      0.0      0.0      0.0\n",
       " 5146 │     0.0      0.0      0.0      0.0      1.0      0.0      0.0      0.0 ⋯\n",
       " 5147 │     1.0      0.0      0.0      1.0      0.0      0.0      0.0      0.0\n",
       " 5148 │     0.0      0.0      0.0      0.0      0.0      1.0      0.0      0.0\n",
       " 5149 │     0.0      0.0      1.0      0.0      0.0      0.0      0.0      0.0\n",
       " 5150 │     0.0      0.0      0.0      0.0      0.0      1.0      0.0      0.0 ⋯\n",
       "\u001b[36m                                                10 columns and 5129 rows omitted\u001b[0m"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading the CSV file into a DataFrame\n",
    "#We have to set the category type for some variable\n",
    "data = CSV.File(\"../../data/wage2015_subsample_inference.csv\"; types = Dict(\"occ\" => String,\"occ2\"=> String,\"ind\"=>String,\"ind2\"=>String)) |> DataFrame\n",
    "println(\"Number of Rows : \", size(data)[1],\"\\n\",\"Number of Columns : \", size(data)[2],) #rows\n",
    "[eltype(col) for col = eachcol(data)]\n",
    "n = size(data)[1]\n",
    "z = select(data, Not([:rownames, :lwage, :wage]))\n",
    "p = size(z)[2] \n",
    "y = data[!, names(data, \"lwage\")]\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ae61baa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Vector{Float64}:\n",
       "  0.08874093642803604\n",
       " -0.006235975855888859\n",
       " -0.15433130990008584\n",
       "  0.165982906183319\n",
       " -1.964787191448247"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = convert(Matrix, Matrix(z[:, 1:5]))\n",
    "Y = convert(Matrix, Matrix(y))\n",
    "lmbda = randn(size(X)[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8df3ddc9",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "MethodError: no method matching fit(::Type{LinearModel}, ::Matrix{Float64}, ::Matrix{Float64}, ::Nothing)\n\u001b[0mClosest candidates are:\n\u001b[0m  fit(::Type{LinearModel}, ::AbstractMatrix{<:Real}, \u001b[91m::AbstractVector{<:Real}\u001b[39m, ::Union{Nothing, Bool}; wts, dropcollinear) at C:\\Users\\Alexander\\.julia\\packages\\GLM\\gt3bb\\src\\lm.jl:161\n\u001b[0m  fit(\u001b[91m::Type{Histogram}\u001b[39m, ::Any...; kwargs...) at C:\\Users\\Alexander\\.julia\\packages\\StatsBase\\pJqvO\\src\\hist.jl:383\n\u001b[0m  fit(::Type{T}, \u001b[91m::FormulaTerm\u001b[39m, ::Any, ::Any...; contrasts, kwargs...) where T<:RegressionModel at C:\\Users\\Alexander\\.julia\\packages\\StatsModels\\57Kc9\\src\\statsmodel.jl:78\n\u001b[0m  ...",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching fit(::Type{LinearModel}, ::Matrix{Float64}, ::Matrix{Float64}, ::Nothing)\n\u001b[0mClosest candidates are:\n\u001b[0m  fit(::Type{LinearModel}, ::AbstractMatrix{<:Real}, \u001b[91m::AbstractVector{<:Real}\u001b[39m, ::Union{Nothing, Bool}; wts, dropcollinear) at C:\\Users\\Alexander\\.julia\\packages\\GLM\\gt3bb\\src\\lm.jl:161\n\u001b[0m  fit(\u001b[91m::Type{Histogram}\u001b[39m, ::Any...; kwargs...) at C:\\Users\\Alexander\\.julia\\packages\\StatsBase\\pJqvO\\src\\hist.jl:383\n\u001b[0m  fit(::Type{T}, \u001b[91m::FormulaTerm\u001b[39m, ::Any, ::Any...; contrasts, kwargs...) where T<:RegressionModel at C:\\Users\\Alexander\\.julia\\packages\\StatsModels\\57Kc9\\src\\statsmodel.jl:78\n\u001b[0m  ...",
      "",
      "Stacktrace:",
      " [1] lm(X::Matrix{Float64}, y::Matrix{Float64}, allowrankdeficient_dep::Nothing; kwargs::Base.Pairs{Symbol, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})",
      "   @ GLM C:\\Users\\Alexander\\.julia\\packages\\GLM\\gt3bb\\src\\lm.jl:184",
      " [2] lm(X::Matrix{Float64}, y::Matrix{Float64}, allowrankdeficient_dep::Nothing) (repeats 2 times)",
      "   @ GLM C:\\Users\\Alexander\\.julia\\packages\\GLM\\gt3bb\\src\\lm.jl:184",
      " [3] top-level scope",
      "   @ In[70]:1",
      " [4] eval",
      "   @ .\\boot.jl:373 [inlined]",
      " [5] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base .\\loading.jl:1196"
     ]
    }
   ],
   "source": [
    "reg = lm(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448b4b83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd9faf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17649142",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c7e3dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef89e629",
   "metadata": {},
   "outputs": [],
   "source": [
    "LassoShooting_fit(X, Y, lmbda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8c4842",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_values(X, Y)[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7f1bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = lm(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b2f82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "LassoShooting_fit(X, Y, lmbda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a19f929",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_values(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7d0575",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2550fe68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m registry at `C:\\Users\\Alexander\\.julia\\registries\\General.toml`\n",
      "┌ Warning: could not download https://pkg.julialang.org/registries\n",
      "│   exception = Downloads.RequestError(\"https://pkg.julialang.org/registries\", 35, \"schannel: failed to receive handshake, SSL/TLS connection failed\", Downloads.Response(\"https\", \"https://sa.pkg.julialang.org/registries\", 301, \"HTTP/1.1 301 SA internal redirect trigger\", [\"connection\" => \"close\", \"content-length\" => \"0\", \"server\" => \"Varnish\", \"retry-after\" => \"0\", \"location\" => \"https://sa.pkg.julialang.org/registries\", \"x-geo-continent\" => \"SA\", \"x-geo-country\" => \"PE\", \"x-geo-region\" => \"CAL\", \"accept-ranges\" => \"bytes\", \"date\" => \"Sun, 13 Mar 2022 15:56:16 GMT\", \"via\" => \"1.1 varnish\", \"x-served-by\" => \"cache-lim12125-LIM\", \"x-cache\" => \"HIT\", \"x-cache-hits\" => \"0\", \"x-timer\" => \"S1647186976.287239,VS0,VE0\"]))\n",
      "└ @ Pkg.Registry C:\\buildbot\\worker\\package_win64\\build\\usr\\share\\julia\\stdlib\\v1.7\\Pkg\\src\\Registry\\Registry.jl:82\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\Alexander\\.julia\\environments\\v1.7\\Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\Alexander\\.julia\\environments\\v1.7\\Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "Unable to automatically install 'Bzip2' from 'C:\\Users\\Alexander\\.julia\\packages\\Bzip2_jll\\iOonP\\Artifacts.toml'",
     "output_type": "error",
     "traceback": [
      "Unable to automatically install 'Bzip2' from 'C:\\Users\\Alexander\\.julia\\packages\\Bzip2_jll\\iOonP\\Artifacts.toml'",
      "",
      "Stacktrace:",
      "  [1] error(s::String)",
      "    @ Base .\\error.jl:33",
      "  [2] ensure_artifact_installed(name::String, meta::Dict{String, Any}, artifacts_toml::String; platform::Base.BinaryPlatforms.Platform, verbose::Bool, quiet_download::Bool, io::IJulia.IJuliaStdio{Base.PipeEndpoint})",
      "    @ Pkg.Artifacts C:\\Users\\Alexander\\AppData\\Local\\Programs\\Julia-1.7.2\\share\\julia\\stdlib\\v1.7\\Pkg\\src\\Artifacts.jl:441",
      "  [3] download_artifacts(env::Pkg.Types.EnvCache; platform::Base.BinaryPlatforms.Platform, julia_version::VersionNumber, verbose::Bool, io::IJulia.IJuliaStdio{Base.PipeEndpoint})",
      "    @ Pkg.Operations C:\\Users\\Alexander\\AppData\\Local\\Programs\\Julia-1.7.2\\share\\julia\\stdlib\\v1.7\\Pkg\\src\\Operations.jl:617",
      "  [4] add(ctx::Pkg.Types.Context, pkgs::Vector{Pkg.Types.PackageSpec}, new_git::Set{Base.UUID}; preserve::Pkg.Types.PreserveLevel, platform::Base.BinaryPlatforms.Platform)",
      "    @ Pkg.Operations C:\\Users\\Alexander\\AppData\\Local\\Programs\\Julia-1.7.2\\share\\julia\\stdlib\\v1.7\\Pkg\\src\\Operations.jl:1182",
      "  [5] add(ctx::Pkg.Types.Context, pkgs::Vector{Pkg.Types.PackageSpec}; preserve::Pkg.Types.PreserveLevel, platform::Base.BinaryPlatforms.Platform, kwargs::Base.Pairs{Symbol, IJulia.IJuliaStdio{Base.PipeEndpoint}, Tuple{Symbol}, NamedTuple{(:io,), Tuple{IJulia.IJuliaStdio{Base.PipeEndpoint}}}})",
      "    @ Pkg.API C:\\Users\\Alexander\\AppData\\Local\\Programs\\Julia-1.7.2\\share\\julia\\stdlib\\v1.7\\Pkg\\src\\API.jl:268",
      "  [6] add(pkgs::Vector{Pkg.Types.PackageSpec}; io::IJulia.IJuliaStdio{Base.PipeEndpoint}, kwargs::Base.Pairs{Symbol, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})",
      "    @ Pkg.API C:\\Users\\Alexander\\AppData\\Local\\Programs\\Julia-1.7.2\\share\\julia\\stdlib\\v1.7\\Pkg\\src\\API.jl:149",
      "  [7] add(pkgs::Vector{Pkg.Types.PackageSpec})",
      "    @ Pkg.API C:\\Users\\Alexander\\AppData\\Local\\Programs\\Julia-1.7.2\\share\\julia\\stdlib\\v1.7\\Pkg\\src\\API.jl:144",
      "  [8] #add#27",
      "    @ C:\\Users\\Alexander\\AppData\\Local\\Programs\\Julia-1.7.2\\share\\julia\\stdlib\\v1.7\\Pkg\\src\\API.jl:142 [inlined]",
      "  [9] add",
      "    @ C:\\Users\\Alexander\\AppData\\Local\\Programs\\Julia-1.7.2\\share\\julia\\stdlib\\v1.7\\Pkg\\src\\API.jl:142 [inlined]",
      " [10] #add#26",
      "    @ C:\\Users\\Alexander\\AppData\\Local\\Programs\\Julia-1.7.2\\share\\julia\\stdlib\\v1.7\\Pkg\\src\\API.jl:141 [inlined]",
      " [11] add(pkg::String)",
      "    @ Pkg.API C:\\Users\\Alexander\\AppData\\Local\\Programs\\Julia-1.7.2\\share\\julia\\stdlib\\v1.7\\Pkg\\src\\API.jl:141",
      " [12] top-level scope",
      "    @ In[1]:2",
      " [13] eval",
      "    @ .\\boot.jl:373 [inlined]",
      " [14] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "    @ Base .\\loading.jl:1196"
     ]
    }
   ],
   "source": [
    "import Pkg; Pkg.add(\"RData\")\n",
    "import Pkg; Pkg.add(\"CodecBzip2\")\n",
    "import Pkg; Pkg.add(\"DataStructures\")\n",
    "import Pkg; Pkg.add(\"NamedArrays\")\n",
    "import Pkg; Pkg.add(\"PrettyTables\")\n",
    "import Pkg; Pkg.add(\"Lasso\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68b73d97",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "HTTP/1.1 302 Found (Send failure: Connection was reset) while requesting https://github.com/JuliaBinaryWrappers/MKL_jll.jl/releases/download/MKL-v2020.0.166%2B0/MKL.v2020.0.166.x86_64-apple-darwin14.tar.gz",
     "output_type": "error",
     "traceback": [
      "HTTP/1.1 302 Found (Send failure: Connection was reset) while requesting https://github.com/JuliaBinaryWrappers/MKL_jll.jl/releases/download/MKL-v2020.0.166%2B0/MKL.v2020.0.166.x86_64-apple-darwin14.tar.gz",
      "",
      "Stacktrace:",
      "  [1] (::Downloads.var\"#9#18\"{IOStream, Base.DevNull, Nothing, Vector{Pair{String, String}}, Float64, Downloads.var\"#24#27\"{Pkg.PlatformEngines.var\"#16#18\"}, Bool, Bool, String, Int64, Bool, Bool})(easy::Downloads.Curl.Easy)",
      "    @ Downloads C:\\Users\\Alexander\\AppData\\Local\\Programs\\Julia-1.7.2\\share\\julia\\stdlib\\v1.7\\Downloads\\src\\Downloads.jl:369",
      "  [2] with_handle(f::Downloads.var\"#9#18\"{IOStream, Base.DevNull, Nothing, Vector{Pair{String, String}}, Float64, Downloads.var\"#24#27\"{Pkg.PlatformEngines.var\"#16#18\"}, Bool, Bool, String, Int64, Bool, Bool}, handle::Downloads.Curl.Easy)",
      "    @ Downloads.Curl C:\\Users\\Alexander\\AppData\\Local\\Programs\\Julia-1.7.2\\share\\julia\\stdlib\\v1.7\\Downloads\\src\\Curl\\Curl.jl:64",
      "  [3] #8",
      "    @ C:\\Users\\Alexander\\AppData\\Local\\Programs\\Julia-1.7.2\\share\\julia\\stdlib\\v1.7\\Downloads\\src\\Downloads.jl:311 [inlined]",
      "  [4] arg_write(f::Downloads.var\"#8#17\"{Base.DevNull, Nothing, Vector{Pair{String, String}}, Float64, Downloads.var\"#24#27\"{Pkg.PlatformEngines.var\"#16#18\"}, Bool, Bool, String, Int64, Bool, Bool}, arg::IOStream)",
      "    @ ArgTools C:\\Users\\Alexander\\AppData\\Local\\Programs\\Julia-1.7.2\\share\\julia\\stdlib\\v1.7\\ArgTools\\src\\ArgTools.jl:112",
      "  [5] #7",
      "    @ C:\\Users\\Alexander\\AppData\\Local\\Programs\\Julia-1.7.2\\share\\julia\\stdlib\\v1.7\\Downloads\\src\\Downloads.jl:310 [inlined]",
      "  [6] arg_read(f::Downloads.var\"#7#16\"{IOStream, Nothing, Vector{Pair{String, String}}, Float64, Downloads.var\"#24#27\"{Pkg.PlatformEngines.var\"#16#18\"}, Bool, Bool, String, Int64, Bool, Bool}, arg::Base.DevNull)",
      "    @ ArgTools C:\\Users\\Alexander\\AppData\\Local\\Programs\\Julia-1.7.2\\share\\julia\\stdlib\\v1.7\\ArgTools\\src\\ArgTools.jl:61",
      "  [7] request(url::String; input::Nothing, output::IOStream, method::Nothing, headers::Vector{Pair{String, String}}, timeout::Float64, progress::Pkg.PlatformEngines.var\"#16#18\", verbose::Bool, throw::Bool, downloader::Nothing)",
      "    @ Downloads C:\\Users\\Alexander\\AppData\\Local\\Programs\\Julia-1.7.2\\share\\julia\\stdlib\\v1.7\\Downloads\\src\\Downloads.jl:309",
      "  [8] #3",
      "    @ C:\\Users\\Alexander\\AppData\\Local\\Programs\\Julia-1.7.2\\share\\julia\\stdlib\\v1.7\\Downloads\\src\\Downloads.jl:222 [inlined]",
      "  [9] open(f::Downloads.var\"#3#4\"{Nothing, Vector{Pair{String, String}}, Float64, Pkg.PlatformEngines.var\"#16#18\", Bool, Nothing, String}, args::String; kwargs::Base.Pairs{Symbol, Bool, Tuple{Symbol}, NamedTuple{(:write,), Tuple{Bool}}})",
      "    @ Base .\\io.jl:330",
      " [10] arg_write(f::Function, arg::String)",
      "    @ ArgTools C:\\Users\\Alexander\\AppData\\Local\\Programs\\Julia-1.7.2\\share\\julia\\stdlib\\v1.7\\ArgTools\\src\\ArgTools.jl:86",
      " [11] #download#2",
      "    @ C:\\Users\\Alexander\\AppData\\Local\\Programs\\Julia-1.7.2\\share\\julia\\stdlib\\v1.7\\Downloads\\src\\Downloads.jl:221 [inlined]",
      " [12] download(url::String, dest::String; verbose::Bool, headers::Vector{Pair{String, String}}, auth_header::Nothing, io::IJulia.IJuliaStdio{Base.PipeEndpoint})",
      "    @ Pkg.PlatformEngines C:\\Users\\Alexander\\AppData\\Local\\Programs\\Julia-1.7.2\\share\\julia\\stdlib\\v1.7\\Pkg\\src\\PlatformEngines.jl:282",
      " [13] top-level scope",
      "    @ In[2]:5",
      " [14] eval",
      "    @ .\\boot.jl:373 [inlined]",
      " [15] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "    @ Base .\\loading.jl:1196"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "\n",
    "Pkg.PlatformEngines.probe_platform_engines!()\n",
    "\n",
    "Pkg.PlatformEngines.download(\"https://github.com/JuliaBinaryWrappers/MKL_jll.jl/releases/download/MKL-v2020.0.166%2B0/MKL.v2020.0.166.x86_64-apple-darwin14.tar.gz\", \"MKL_jll.tar.gz\"; verbose=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e465a62c",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "syntax: invalid operator \"--\"",
     "output_type": "error",
     "traceback": [
      "syntax: invalid operator \"--\"",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[3]:1",
      " [2] eval",
      "   @ .\\boot.jl:373 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base .\\loading.jl:1196"
     ]
    }
   ],
   "source": [
    "curl --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29a4d1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "using RData, LinearAlgebra, GLM, DataFrames, Statistics, Random, Distributions, DataStructures, NamedArrays, PrettyTables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8eb05ff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{String, Any} with 1 entry:\n",
       "  \"GrowthData\" => \u001b[1m90×63 DataFrame\u001b[0m…"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing .Rdata file\n",
    "growth_read = load(\"../../data/GrowthData.RData\")\n",
    "\n",
    "# Since growth_read is a dictionary, we check if there is a key called \"GrowthData\", the one we need for our analyze\n",
    "haskey(growth_read, \"GrowthData\")\n",
    "# Now we save that dataframe with a new name\n",
    "growth = growth_read[\"GrowthData\"]\n",
    "names(growth)\n",
    "\n",
    "Y = growth[!, \"Outcome\"]\n",
    "Y_2 = DataFrame([Y], [:Y])\n",
    "X_2 = select(growth, Not([\"Outcome\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fdb78cbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>90 rows × 62 columns (omitted printing of 53 columns)</p><table class=\"data-frame\"><thead><tr><th></th><th>intercept</th><th>gdpsh465</th><th>bmp1l</th><th>freeop</th><th>freetar</th><th>h65</th><th>hm65</th><th>hf65</th><th>p65</th></tr><tr><th></th><th title=\"Int32\">Int32</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th></tr></thead><tbody><tr><th>1</th><td>1</td><td>6.59167</td><td>0.2837</td><td>0.153491</td><td>0.043888</td><td>0.007</td><td>0.013</td><td>0.001</td><td>0.29</td></tr><tr><th>2</th><td>1</td><td>6.82979</td><td>0.6141</td><td>0.313509</td><td>0.061827</td><td>0.019</td><td>0.032</td><td>0.007</td><td>0.91</td></tr><tr><th>3</th><td>1</td><td>8.89508</td><td>0.0</td><td>0.204244</td><td>0.009186</td><td>0.26</td><td>0.325</td><td>0.201</td><td>1.0</td></tr><tr><th>4</th><td>1</td><td>7.56528</td><td>0.1997</td><td>0.248714</td><td>0.03627</td><td>0.061</td><td>0.07</td><td>0.051</td><td>1.0</td></tr><tr><th>5</th><td>1</td><td>7.1624</td><td>0.174</td><td>0.299252</td><td>0.037367</td><td>0.017</td><td>0.027</td><td>0.007</td><td>0.82</td></tr><tr><th>6</th><td>1</td><td>7.21891</td><td>0.0</td><td>0.258865</td><td>0.02088</td><td>0.023</td><td>0.038</td><td>0.006</td><td>0.5</td></tr><tr><th>7</th><td>1</td><td>7.8536</td><td>0.0</td><td>0.182525</td><td>0.014385</td><td>0.039</td><td>0.063</td><td>0.014</td><td>0.92</td></tr><tr><th>8</th><td>1</td><td>7.70391</td><td>0.2776</td><td>0.215275</td><td>0.029713</td><td>0.024</td><td>0.035</td><td>0.013</td><td>0.69</td></tr><tr><th>9</th><td>1</td><td>9.06346</td><td>0.0</td><td>0.109614</td><td>0.002171</td><td>0.402</td><td>0.488</td><td>0.314</td><td>1.0</td></tr><tr><th>10</th><td>1</td><td>8.15191</td><td>0.1484</td><td>0.110885</td><td>0.028579</td><td>0.145</td><td>0.173</td><td>0.114</td><td>1.0</td></tr><tr><th>11</th><td>1</td><td>6.92952</td><td>0.0296</td><td>0.165784</td><td>0.020115</td><td>0.046</td><td>0.066</td><td>0.025</td><td>0.73</td></tr><tr><th>12</th><td>1</td><td>7.23778</td><td>0.2151</td><td>0.078488</td><td>0.011581</td><td>0.022</td><td>0.031</td><td>0.014</td><td>1.0</td></tr><tr><th>13</th><td>1</td><td>8.11582</td><td>0.4318</td><td>0.137482</td><td>0.026547</td><td>0.059</td><td>0.073</td><td>0.045</td><td>1.0</td></tr><tr><th>14</th><td>1</td><td>7.2717</td><td>0.1689</td><td>0.164598</td><td>0.044446</td><td>0.029</td><td>0.045</td><td>0.013</td><td>0.84</td></tr><tr><th>15</th><td>1</td><td>7.12125</td><td>0.1832</td><td>0.188016</td><td>0.045678</td><td>0.033</td><td>0.051</td><td>0.015</td><td>0.91</td></tr><tr><th>16</th><td>1</td><td>6.97728</td><td>0.0962</td><td>0.204611</td><td>0.077852</td><td>0.037</td><td>0.043</td><td>0.03</td><td>1.0</td></tr><tr><th>17</th><td>1</td><td>7.64969</td><td>0.0227</td><td>0.136287</td><td>0.04673</td><td>0.081</td><td>0.105</td><td>0.056</td><td>0.99</td></tr><tr><th>18</th><td>1</td><td>8.05674</td><td>0.0208</td><td>0.197853</td><td>0.037224</td><td>0.083</td><td>0.097</td><td>0.069</td><td>1.0</td></tr><tr><th>19</th><td>1</td><td>8.78094</td><td>0.2654</td><td>0.189867</td><td>0.031747</td><td>0.068</td><td>0.089</td><td>0.046</td><td>0.94</td></tr><tr><th>20</th><td>1</td><td>6.28786</td><td>0.4207</td><td>0.130682</td><td>0.109921</td><td>0.053</td><td>0.039</td><td>0.011</td><td>0.74</td></tr><tr><th>21</th><td>1</td><td>6.13773</td><td>0.1371</td><td>0.123818</td><td>0.015897</td><td>0.028</td><td>0.025</td><td>0.007</td><td>0.72</td></tr><tr><th>22</th><td>1</td><td>8.12888</td><td>0.0</td><td>0.16721</td><td>0.003311</td><td>0.129</td><td>0.196</td><td>0.063</td><td>1.0</td></tr><tr><th>23</th><td>1</td><td>6.68085</td><td>0.4713</td><td>0.228424</td><td>0.029328</td><td>0.062</td><td>0.09</td><td>0.032</td><td>1.0</td></tr><tr><th>24</th><td>1</td><td>7.17702</td><td>0.0178</td><td>0.18524</td><td>0.015453</td><td>0.02</td><td>0.026</td><td>0.013</td><td>0.9</td></tr><tr><th>25</th><td>1</td><td>6.64898</td><td>0.4762</td><td>0.171181</td><td>0.058937</td><td>0.018</td><td>0.028</td><td>0.007</td><td>0.4</td></tr><tr><th>26</th><td>1</td><td>6.87936</td><td>0.2927</td><td>0.179508</td><td>0.035842</td><td>0.188</td><td>0.169</td><td>0.208</td><td>1.0</td></tr><tr><th>27</th><td>1</td><td>7.3473</td><td>0.1017</td><td>0.247626</td><td>0.037392</td><td>0.08</td><td>0.133</td><td>0.027</td><td>0.78</td></tr><tr><th>28</th><td>1</td><td>6.72503</td><td>0.0266</td><td>0.179933</td><td>0.046376</td><td>0.015</td><td>0.02</td><td>0.01</td><td>0.78</td></tr><tr><th>29</th><td>1</td><td>8.45105</td><td>0.0</td><td>0.358556</td><td>0.016468</td><td>0.09</td><td>0.133</td><td>0.044</td><td>1.0</td></tr><tr><th>30</th><td>1</td><td>8.60245</td><td>0.0</td><td>0.416234</td><td>0.014721</td><td>0.148</td><td>0.194</td><td>0.1</td><td>1.0</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccccccc}\n",
       "\t& intercept & gdpsh465 & bmp1l & freeop & freetar & h65 & hm65 & hf65 & p65 & \\\\\n",
       "\t\\hline\n",
       "\t& Int32 & Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & \\\\\n",
       "\t\\hline\n",
       "\t1 & 1 & 6.59167 & 0.2837 & 0.153491 & 0.043888 & 0.007 & 0.013 & 0.001 & 0.29 & $\\dots$ \\\\\n",
       "\t2 & 1 & 6.82979 & 0.6141 & 0.313509 & 0.061827 & 0.019 & 0.032 & 0.007 & 0.91 & $\\dots$ \\\\\n",
       "\t3 & 1 & 8.89508 & 0.0 & 0.204244 & 0.009186 & 0.26 & 0.325 & 0.201 & 1.0 & $\\dots$ \\\\\n",
       "\t4 & 1 & 7.56528 & 0.1997 & 0.248714 & 0.03627 & 0.061 & 0.07 & 0.051 & 1.0 & $\\dots$ \\\\\n",
       "\t5 & 1 & 7.1624 & 0.174 & 0.299252 & 0.037367 & 0.017 & 0.027 & 0.007 & 0.82 & $\\dots$ \\\\\n",
       "\t6 & 1 & 7.21891 & 0.0 & 0.258865 & 0.02088 & 0.023 & 0.038 & 0.006 & 0.5 & $\\dots$ \\\\\n",
       "\t7 & 1 & 7.8536 & 0.0 & 0.182525 & 0.014385 & 0.039 & 0.063 & 0.014 & 0.92 & $\\dots$ \\\\\n",
       "\t8 & 1 & 7.70391 & 0.2776 & 0.215275 & 0.029713 & 0.024 & 0.035 & 0.013 & 0.69 & $\\dots$ \\\\\n",
       "\t9 & 1 & 9.06346 & 0.0 & 0.109614 & 0.002171 & 0.402 & 0.488 & 0.314 & 1.0 & $\\dots$ \\\\\n",
       "\t10 & 1 & 8.15191 & 0.1484 & 0.110885 & 0.028579 & 0.145 & 0.173 & 0.114 & 1.0 & $\\dots$ \\\\\n",
       "\t11 & 1 & 6.92952 & 0.0296 & 0.165784 & 0.020115 & 0.046 & 0.066 & 0.025 & 0.73 & $\\dots$ \\\\\n",
       "\t12 & 1 & 7.23778 & 0.2151 & 0.078488 & 0.011581 & 0.022 & 0.031 & 0.014 & 1.0 & $\\dots$ \\\\\n",
       "\t13 & 1 & 8.11582 & 0.4318 & 0.137482 & 0.026547 & 0.059 & 0.073 & 0.045 & 1.0 & $\\dots$ \\\\\n",
       "\t14 & 1 & 7.2717 & 0.1689 & 0.164598 & 0.044446 & 0.029 & 0.045 & 0.013 & 0.84 & $\\dots$ \\\\\n",
       "\t15 & 1 & 7.12125 & 0.1832 & 0.188016 & 0.045678 & 0.033 & 0.051 & 0.015 & 0.91 & $\\dots$ \\\\\n",
       "\t16 & 1 & 6.97728 & 0.0962 & 0.204611 & 0.077852 & 0.037 & 0.043 & 0.03 & 1.0 & $\\dots$ \\\\\n",
       "\t17 & 1 & 7.64969 & 0.0227 & 0.136287 & 0.04673 & 0.081 & 0.105 & 0.056 & 0.99 & $\\dots$ \\\\\n",
       "\t18 & 1 & 8.05674 & 0.0208 & 0.197853 & 0.037224 & 0.083 & 0.097 & 0.069 & 1.0 & $\\dots$ \\\\\n",
       "\t19 & 1 & 8.78094 & 0.2654 & 0.189867 & 0.031747 & 0.068 & 0.089 & 0.046 & 0.94 & $\\dots$ \\\\\n",
       "\t20 & 1 & 6.28786 & 0.4207 & 0.130682 & 0.109921 & 0.053 & 0.039 & 0.011 & 0.74 & $\\dots$ \\\\\n",
       "\t21 & 1 & 6.13773 & 0.1371 & 0.123818 & 0.015897 & 0.028 & 0.025 & 0.007 & 0.72 & $\\dots$ \\\\\n",
       "\t22 & 1 & 8.12888 & 0.0 & 0.16721 & 0.003311 & 0.129 & 0.196 & 0.063 & 1.0 & $\\dots$ \\\\\n",
       "\t23 & 1 & 6.68085 & 0.4713 & 0.228424 & 0.029328 & 0.062 & 0.09 & 0.032 & 1.0 & $\\dots$ \\\\\n",
       "\t24 & 1 & 7.17702 & 0.0178 & 0.18524 & 0.015453 & 0.02 & 0.026 & 0.013 & 0.9 & $\\dots$ \\\\\n",
       "\t25 & 1 & 6.64898 & 0.4762 & 0.171181 & 0.058937 & 0.018 & 0.028 & 0.007 & 0.4 & $\\dots$ \\\\\n",
       "\t26 & 1 & 6.87936 & 0.2927 & 0.179508 & 0.035842 & 0.188 & 0.169 & 0.208 & 1.0 & $\\dots$ \\\\\n",
       "\t27 & 1 & 7.3473 & 0.1017 & 0.247626 & 0.037392 & 0.08 & 0.133 & 0.027 & 0.78 & $\\dots$ \\\\\n",
       "\t28 & 1 & 6.72503 & 0.0266 & 0.179933 & 0.046376 & 0.015 & 0.02 & 0.01 & 0.78 & $\\dots$ \\\\\n",
       "\t29 & 1 & 8.45105 & 0.0 & 0.358556 & 0.016468 & 0.09 & 0.133 & 0.044 & 1.0 & $\\dots$ \\\\\n",
       "\t30 & 1 & 8.60245 & 0.0 & 0.416234 & 0.014721 & 0.148 & 0.194 & 0.1 & 1.0 & $\\dots$ \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m90×62 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m intercept \u001b[0m\u001b[1m gdpsh465 \u001b[0m\u001b[1m bmp1l   \u001b[0m\u001b[1m freeop   \u001b[0m\u001b[1m freetar  \u001b[0m\u001b[1m h65     \u001b[0m\u001b[1m hm65    \u001b[0m\u001b[1m hf6\u001b[0m ⋯\n",
       "\u001b[1m     \u001b[0m│\u001b[90m Int32     \u001b[0m\u001b[90m Float64  \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64  \u001b[0m\u001b[90m Float64  \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Flo\u001b[0m ⋯\n",
       "─────┼──────────────────────────────────────────────────────────────────────────\n",
       "   1 │         1   6.59167   0.2837  0.153491  0.043888    0.007    0.013    0 ⋯\n",
       "   2 │         1   6.82979   0.6141  0.313509  0.061827    0.019    0.032    0\n",
       "   3 │         1   8.89508   0.0     0.204244  0.009186    0.26     0.325    0\n",
       "   4 │         1   7.56528   0.1997  0.248714  0.03627     0.061    0.07     0\n",
       "   5 │         1   7.1624    0.174   0.299252  0.037367    0.017    0.027    0 ⋯\n",
       "   6 │         1   7.21891   0.0     0.258865  0.02088     0.023    0.038    0\n",
       "   7 │         1   7.8536    0.0     0.182525  0.014385    0.039    0.063    0\n",
       "   8 │         1   7.70391   0.2776  0.215275  0.029713    0.024    0.035    0\n",
       "   9 │         1   9.06346   0.0     0.109614  0.002171    0.402    0.488    0 ⋯\n",
       "  10 │         1   8.15191   0.1484  0.110885  0.028579    0.145    0.173    0\n",
       "  11 │         1   6.92952   0.0296  0.165784  0.020115    0.046    0.066    0\n",
       "  ⋮  │     ⋮         ⋮         ⋮        ⋮         ⋮         ⋮        ⋮         ⋱\n",
       "  81 │         1   9.03097   0.0     0.293138  0.005517    0.245    0.251    0\n",
       "  82 │         1   8.99554   0.0     0.30472   0.011658    0.246    0.26     0 ⋯\n",
       "  83 │         1   8.23483   0.0363  0.288405  0.011589    0.183    0.222    0\n",
       "  84 │         1   8.33255   0.0     0.345485  0.006503    0.188    0.248    0\n",
       "  85 │         1   8.64559   0.0     0.28844   0.005995    0.256    0.301    0\n",
       "  86 │         1   8.99106   0.0     0.371898  0.014586    0.255    0.336    0 ⋯\n",
       "  87 │         1   8.02519   0.005   0.296437  0.013615    0.108    0.117    0\n",
       "  88 │         1   9.03014   0.0     0.265778  0.008629    0.288    0.337    0\n",
       "  89 │         1   8.86531   0.0     0.282939  0.005048    0.188    0.236    0\n",
       "  90 │         1   8.91234   0.0     0.150366  0.024377    0.257    0.338    0 ⋯\n",
       "\u001b[36m                                                  55 columns and 69 rows omitted\u001b[0m"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1e89c53a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Vector{Float64}:\n",
       "  0.2453949358186934\n",
       " -0.08642608748746254\n",
       " -0.6178751708887436\n",
       " -0.23957066264789037"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_2 = convert(Matrix, Matrix(X_2[:, 2:5]))\n",
    "Y_2 = convert(Matrix, Matrix(Y_2))\n",
    "lmbda = randn(size(X_2)[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bcdb5b8e",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "MethodError: no method matching fit(::Type{LinearModel}, ::Matrix{Float64}, ::Matrix{Float64}, ::Nothing)\n\u001b[0mClosest candidates are:\n\u001b[0m  fit(::Type{LinearModel}, ::AbstractMatrix{<:Real}, \u001b[91m::AbstractVector{<:Real}\u001b[39m, ::Union{Nothing, Bool}; wts, dropcollinear) at C:\\Users\\Alexander\\.julia\\packages\\GLM\\gt3bb\\src\\lm.jl:161\n\u001b[0m  fit(\u001b[91m::Type{StatsBase.Histogram}\u001b[39m, ::Any...; kwargs...) at C:\\Users\\Alexander\\.julia\\packages\\StatsBase\\pJqvO\\src\\hist.jl:383\n\u001b[0m  fit(::Type{T}, \u001b[91m::FormulaTerm\u001b[39m, ::Any, ::Any...; contrasts, kwargs...) where T<:RegressionModel at C:\\Users\\Alexander\\.julia\\packages\\StatsModels\\57Kc9\\src\\statsmodel.jl:78\n\u001b[0m  ...",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching fit(::Type{LinearModel}, ::Matrix{Float64}, ::Matrix{Float64}, ::Nothing)\n\u001b[0mClosest candidates are:\n\u001b[0m  fit(::Type{LinearModel}, ::AbstractMatrix{<:Real}, \u001b[91m::AbstractVector{<:Real}\u001b[39m, ::Union{Nothing, Bool}; wts, dropcollinear) at C:\\Users\\Alexander\\.julia\\packages\\GLM\\gt3bb\\src\\lm.jl:161\n\u001b[0m  fit(\u001b[91m::Type{StatsBase.Histogram}\u001b[39m, ::Any...; kwargs...) at C:\\Users\\Alexander\\.julia\\packages\\StatsBase\\pJqvO\\src\\hist.jl:383\n\u001b[0m  fit(::Type{T}, \u001b[91m::FormulaTerm\u001b[39m, ::Any, ::Any...; contrasts, kwargs...) where T<:RegressionModel at C:\\Users\\Alexander\\.julia\\packages\\StatsModels\\57Kc9\\src\\statsmodel.jl:78\n\u001b[0m  ...",
      "",
      "Stacktrace:",
      " [1] lm(X::Matrix{Float64}, y::Matrix{Float64}, allowrankdeficient_dep::Nothing; kwargs::Base.Pairs{Symbol, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})",
      "   @ GLM C:\\Users\\Alexander\\.julia\\packages\\GLM\\gt3bb\\src\\lm.jl:184",
      " [2] lm(X::Matrix{Float64}, y::Matrix{Float64}, allowrankdeficient_dep::Nothing) (repeats 2 times)",
      "   @ GLM C:\\Users\\Alexander\\.julia\\packages\\GLM\\gt3bb\\src\\lm.jl:184",
      " [3] top-level scope",
      "   @ In[29]:1",
      " [4] eval",
      "   @ .\\boot.jl:373 [inlined]",
      " [5] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base .\\loading.jl:1196"
     ]
    }
   ],
   "source": [
    "lm(X_2, Y_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a08b9932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90×4 Matrix{Float64}:\n",
       " 6.59167  0.2837  0.153491  0.043888\n",
       " 6.82979  0.6141  0.313509  0.061827\n",
       " 8.89508  0.0     0.204244  0.009186\n",
       " 7.56528  0.1997  0.248714  0.03627\n",
       " 7.1624   0.174   0.299252  0.037367\n",
       " 7.21891  0.0     0.258865  0.02088\n",
       " 7.8536   0.0     0.182525  0.014385\n",
       " 7.70391  0.2776  0.215275  0.029713\n",
       " 9.06346  0.0     0.109614  0.002171\n",
       " 8.15191  0.1484  0.110885  0.028579\n",
       " 6.92952  0.0296  0.165784  0.020115\n",
       " 7.23778  0.2151  0.078488  0.011581\n",
       " 8.11582  0.4318  0.137482  0.026547\n",
       " ⋮                          \n",
       " 7.89469  0.1062  0.247626  0.037392\n",
       " 7.17549  0.0     0.179933  0.046376\n",
       " 9.03097  0.0     0.293138  0.005517\n",
       " 8.99554  0.0     0.30472   0.011658\n",
       " 8.23483  0.0363  0.288405  0.011589\n",
       " 8.33255  0.0     0.345485  0.006503\n",
       " 8.64559  0.0     0.28844   0.005995\n",
       " 8.99106  0.0     0.371898  0.014586\n",
       " 8.02519  0.005   0.296437  0.013615\n",
       " 9.03014  0.0     0.265778  0.008629\n",
       " 8.86531  0.0     0.282939  0.005048\n",
       " 8.91234  0.0     0.150366  0.024377"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5c00f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.2",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
