{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25600ba7",
   "metadata": {
    "_execution_state": "idle",
    "_uuid": "051d70d956493feee0c6d64651c6a088724dca2a",
    "papermill": {
     "duration": 0.006668,
     "end_time": "2021-02-04T12:17:27.298263",
     "exception": false,
     "start_time": "2021-02-04T12:17:27.291595",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This notebook contains an example for teaching."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087316b5",
   "metadata": {
    "papermill": {
     "duration": 0.005558,
     "end_time": "2021-02-04T12:17:27.309488",
     "exception": false,
     "start_time": "2021-02-04T12:17:27.303930",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# The Effect of Gun Ownership on Gun-Homicide Rates - proceeding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da09851d",
   "metadata": {
    "papermill": {
     "duration": 0.005661,
     "end_time": "2021-02-04T12:17:27.320615",
     "exception": false,
     "start_time": "2021-02-04T12:17:27.314954",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In this lab, we estimate the effect of gun ownership on the homicide rate by a neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6089ed1f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AlreadyExistsError",
     "evalue": "Another metric with the same name already exists.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAlreadyExistsError\u001b[0m                        Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpatsy\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m loadtxt\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dense\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mhdmpy\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\__init__.py:25\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# See b/110718070#comment18 for more details about this import.\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m models\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minput_layer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Input\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msequential\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\models.py:20\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m metrics \u001b[38;5;28;01mas\u001b[39;00m metrics_module\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m optimizer_v1\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m functional\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\metrics.py:24\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m List, Tuple, Union\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m activations\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m base_layer\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\activations.py:20\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m advanced_activations\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeneric_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deserialize_keras_object\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeneric_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m serialize_keras_object\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\layers\\__init__.py:23\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf2\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Generic layers.\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minput_layer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Input\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minput_layer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InputLayer\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minput_spec\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InputSpec\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\input_layer.py:21\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distributed_training_utils\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m base_layer\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras_tensor\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m node \u001b[38;5;28;01mas\u001b[39;00m node_module\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\base_layer.py:43\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m node \u001b[38;5;28;01mas\u001b[39;00m node_module\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmixed_precision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m autocast_variable\n\u001b[1;32m---> 43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmixed_precision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m loss_scale_optimizer\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmixed_precision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m policy\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaved_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layer_serialization\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\mixed_precision\\loss_scale_optimizer.py:18\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Contains the loss scaling optimizer class.\"\"\"\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m optimizers\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmixed_precision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m loss_scale \u001b[38;5;28;01mas\u001b[39;00m keras_loss_scale_module\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizer_experimental\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m optimizer \u001b[38;5;28;01mas\u001b[39;00m optimizer_experimental\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizers.py:31\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizer_v1\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Optimizer\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizer_v1\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TFOptimizer\n\u001b[1;32m---> 31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizer_v2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m adadelta \u001b[38;5;28;01mas\u001b[39;00m adadelta_v2\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizer_v2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m adagrad \u001b[38;5;28;01mas\u001b[39;00m adagrad_v2\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizer_v2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m adam \u001b[38;5;28;01mas\u001b[39;00m adam_v2\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizer_v2\\adadelta.py:22\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend_config\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizer_v2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m optimizer_v2\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtf_export\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras_export\n\u001b[0;32m     26\u001b[0m \u001b[38;5;129m@keras_export\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeras.optimizers.Adadelta\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mAdadelta\u001b[39;00m(optimizer_v2\u001b[38;5;241m.\u001b[39mOptimizerV2):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:36\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtf_export\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras_export\n\u001b[1;32m---> 36\u001b[0m keras_optimizers_gauge \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__internal__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmonitoring\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBoolGauge\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/tensorflow/api/keras/optimizers\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mkeras optimizer usage\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmethod\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m _DEFAULT_VALID_DTYPES \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfrozenset\u001b[39m([\n\u001b[0;32m     40\u001b[0m     tf\u001b[38;5;241m.\u001b[39mfloat16, tf\u001b[38;5;241m.\u001b[39mbfloat16, tf\u001b[38;5;241m.\u001b[39mfloat32, tf\u001b[38;5;241m.\u001b[39mfloat64,\n\u001b[0;32m     41\u001b[0m     tf\u001b[38;5;241m.\u001b[39mcomplex64, tf\u001b[38;5;241m.\u001b[39mcomplex128\n\u001b[0;32m     42\u001b[0m ])\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_deduplicate_indexed_slices\u001b[39m(values, indices):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\monitoring.py:360\u001b[0m, in \u001b[0;36mBoolGauge.__init__\u001b[1;34m(self, name, description, *labels)\u001b[0m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, description, \u001b[38;5;241m*\u001b[39mlabels):\n\u001b[0;32m    353\u001b[0m   \u001b[38;5;124;03m\"\"\"Creates a new BoolGauge.\u001b[39;00m\n\u001b[0;32m    354\u001b[0m \n\u001b[0;32m    355\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    358\u001b[0m \u001b[38;5;124;03m    *labels: The label list of the new metric.\u001b[39;00m\n\u001b[0;32m    359\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 360\u001b[0m   \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mBoolGauge\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBoolGauge\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_bool_gauge_methods\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    361\u001b[0m \u001b[43m                                  \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\monitoring.py:135\u001b[0m, in \u001b[0;36mMetric.__init__\u001b[1;34m(self, metric_name, metric_methods, label_length, *args)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m label_length \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metric_methods):\n\u001b[0;32m    132\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCannot create \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m metric with label >= \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    133\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metric_name, \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metric_methods)))\n\u001b[1;32m--> 135\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metric \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_metric_methods\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_label_length\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mAlreadyExistsError\u001b[0m: Another metric with the same name already exists."
     ]
    }
   ],
   "source": [
    "# Import relevant packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyreadr\n",
    "from sklearn import preprocessing\n",
    "import patsy\n",
    "\n",
    "from numpy import loadtxt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "import hdmpy\n",
    "import numpy as np\n",
    "import random\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib import colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6897820d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import RidgeCV, ElasticNetCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import linear_model\n",
    "import itertools\n",
    "from pandas.api.types import is_string_dtype\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "from pandas.api.types import is_categorical_dtype\n",
    "from itertools import compress\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa65189d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "415"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = pd.read_csv( r\"../data/gun_clean.csv\" )\n",
    "data1.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9ffdfa",
   "metadata": {
    "papermill": {
     "duration": 0.017216,
     "end_time": "2021-02-13T17:30:14.432656",
     "exception": false,
     "start_time": "2021-02-13T17:30:14.415440",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0757f7b",
   "metadata": {
    "papermill": {
     "duration": 0.017212,
     "end_time": "2021-02-13T17:30:14.467075",
     "exception": false,
     "start_time": "2021-02-13T17:30:14.449863",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "To account for heterogeneity across counties and time trends in  all variables, we remove from them county-specific and time-specific effects in the following preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "633cd7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0f7015c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-820c967e63f7>:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  rdata[f'{var_name}'] = smf.ols( formula = form , data = data1 ).fit().resid\n"
     ]
    }
   ],
   "source": [
    "#################################  Find Variable Names from Dataset ########################\n",
    "\n",
    "def varlist( df = None, type_dataframe = [ 'numeric' , 'categorical' , 'string' ],  pattern = \"\", exclude = None ):\n",
    "    varrs = []\n",
    "    \n",
    "    if ('numeric' in type_dataframe):\n",
    "        varrs = varrs + df.columns[ df.apply( is_numeric_dtype , axis = 0 ).to_list() ].tolist()\n",
    "    \n",
    "    if ('categorical' in type_dataframe):\n",
    "        varrs = varrs + df.columns[ df.apply( is_categorical_dtype , axis = 0 ).to_list() ].tolist()\n",
    "    \n",
    "    if ('string' in type_dataframe):\n",
    "        varrs = varrs + df.columns[ df.apply( is_string_dtype , axis = 0 ).to_list() ].tolist()\n",
    "    \n",
    "    grepl_result = np.array( [ re.search( pattern , variable ) is not None for variable in df.columns.to_list() ] )\n",
    "    \n",
    "    if exclude is None:\n",
    "        result = list(compress( varrs, grepl_result ) )\n",
    "    \n",
    "    else:\n",
    "        varrs_excluded = np.array( [var in exclude for var in varrs ] )\n",
    "        and_filter = np.logical_and( ~varrs_excluded ,  grepl_result )\n",
    "        result = list(compress( varrs, and_filter ) )\n",
    "    \n",
    "    return result   \n",
    "\n",
    "################################# Create Variables ###############################\n",
    "\n",
    "\n",
    "# Dummy Variables for Year and County Fixed Effects\n",
    "r = re.compile(\"X_Jfips\")\n",
    "fixed = list( filter( r.match, data1.columns.to_list() ) )\n",
    "year = varlist(data1, pattern=\"X_Tyear\")\n",
    "\n",
    "census = []\n",
    "census_var = [\"^AGE\", \"^BN\", \"^BP\", \"^BZ\", \"^ED\", \"^EL\",\"^HI\", \"^HS\", \"^INC\", \"^LF\", \"^LN\", \"^PI\", \"^PO\", \"^PP\", \"^PV\", \"^SPR\", \"^VS\"]\n",
    "\n",
    "for variable in census_var:\n",
    "    r = re.compile( variable )\n",
    "    census = census + list( filter( r.match, data1.columns.to_list() ) )\n",
    "\n",
    "    \n",
    "################################ Variables ##################################\n",
    "# Treatment Variable\n",
    "d = \"logfssl\"\n",
    "\n",
    "# Outcome Variable\n",
    "y = \"logghomr\"\n",
    "\n",
    "# Other Control Variables\n",
    "X1 = [\"logrobr\", \"logburg\", \"burg_missing\", \"robrate_missing\"]\n",
    "X2 = [\"newblack\", \"newfhh\", \"newmove\", \"newdens\", \"newmal\"]\n",
    "\n",
    "#################################  Partial out Fixed Effects ########################\n",
    "\n",
    "rdata = data1[['CountyCode']]\n",
    "\n",
    "# Variables to be Partialled-out\n",
    "varlist2 = [y] + [d] + X1 + X2 + census\n",
    "\n",
    "# Partial out Variables in varlist from year and county fixed effect\n",
    "for var_name in varlist2:\n",
    "    form = var_name + \" ~ \" + \"+\" + \" + \".join( year ) + \"+\" + \" + \".join( fixed )\n",
    "    rdata[f'{var_name}'] = smf.ols( formula = form , data = data1 ).fit().resid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c981806",
   "metadata": {
    "papermill": {
     "duration": 0.006178,
     "end_time": "2021-02-04T12:17:53.609824",
     "exception": false,
     "start_time": "2021-02-04T12:17:53.603646",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# DML for neural nets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971f799e",
   "metadata": {
    "papermill": {
     "duration": 0.005978,
     "end_time": "2021-02-04T12:17:53.621881",
     "exception": false,
     "start_time": "2021-02-04T12:17:53.615903",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The following algorithm comsumes $Y$,$D$ and $Z$, and learns the residuals $\\tilde{Y}$ and $\\tilde{D}$ via a neural network, where the residuals are obtained by cross-validation (cross-fitting). Then, it prints the estimated coefficient β and the clustered standard error from the final OLS regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a1cf0aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "208be5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DML2_for_NN(z, d, y, nfold, clu, num_epochs, batch_size):\n",
    "    \n",
    "    # Num ob observations\n",
    "    nobs = z.shape[0]\n",
    "    \n",
    "    # Define folds indices \n",
    "    list_1 = [*range(0, nfold, 1)]*nobs\n",
    "    sample = np.random.choice(nobs,nobs, replace=False).tolist()\n",
    "    foldid = [list_1[index] for index in sample]\n",
    "\n",
    "    # Create split function(similar to R)\n",
    "    def split(x, f):\n",
    "        count = max(f) + 1\n",
    "        return tuple( list(itertools.compress(x, (el == i for el in f))) for i in range(count) ) \n",
    "\n",
    "    # Split observation indices into folds \n",
    "    list_2 = [*range(0, nobs, 1)]\n",
    "    I = split(list_2, foldid)\n",
    "    \n",
    "    # loop to save results\n",
    "    for b in range(0,len(I)):\n",
    "    \n",
    "        # Split data - index to keep are in mask as booleans\n",
    "        include_idx = set(I[b])  #Here should go I[b] Set is more efficient, but doesn't reorder your elements if that is desireable\n",
    "        mask = np.array([(i in include_idx) for i in range(len(z))])\n",
    "\n",
    "        # Normalize the data\n",
    "        scaler = StandardScaler()\n",
    "        \n",
    "        scaler.fit( z[~mask,] )\n",
    "        z[~mask,] = scaler.transform( z[~mask,] )\n",
    "\n",
    "        scaler.fit( z[mask,] )\n",
    "        z[mask,] = scaler.transform( z[mask,] )\n",
    "        \n",
    "        # building the model\n",
    "        # define the keras model\n",
    "        model = Sequential()\n",
    "        model.add(Dense(16, input_dim = z[~mask,].shape[1], activation = 'relu'))\n",
    "        model.add(Dense(16, activation = 'relu'))\n",
    "        model.add(Dense(1))\n",
    "        \n",
    "        # compile the keras model\n",
    "        opt = keras.optimizers.RMSprop()\n",
    "        mse = tf.keras.losses.MeanSquaredError()\n",
    "        mae = tf.keras.metrics.MeanAbsoluteError(name=\"mean_absolute_error\", dtype=None)\n",
    "        model.compile(loss=mse, optimizer= opt , metrics=mae)\n",
    "\n",
    "        # Fit and predict dhat\n",
    "        model.fit(z[~mask,], d[~mask,], epochs=num_epochs, batch_size=batch_size, verbose = 0)\n",
    "        dhat = model.predict(z[mask,])\n",
    "        \n",
    "        # Fit and predict yhat\n",
    "        model.fit(z[~mask,], y[~mask,], epochs=num_epochs, batch_size=batch_size, verbose = 0)\n",
    "        yhat = model.predict(z[mask,])\n",
    "\n",
    "        # Create array to save errors \n",
    "        dtil = np.zeros( len(z) ).reshape( len(z) , 1 )\n",
    "        ytil = np.zeros( len(z) ).reshape( len(z) , 1 )\n",
    "\n",
    "        # save errors  \n",
    "        dtil[mask] =  d[mask,] - dhat.reshape( len(I[b]) , 1 )\n",
    "        ytil[mask] = y[mask,] - yhat.reshape( len(I[b]) , 1 )\n",
    "        print(b, \" \")\n",
    "    \n",
    "    # Create dataframe \n",
    "    data_2 = pd.DataFrame(np.concatenate( ( ytil, dtil,clu ), axis = 1), columns = ['ytil','dtil','CountyCode'])\n",
    "   \n",
    "    # OLS clustering at the County level\n",
    "    model = \"ytil ~ dtil\"\n",
    "    rfit = smf.ols(model , data=data_2).fit().get_robustcov_results(cov_type = \"cluster\", groups= data_2['CountyCode'])\n",
    "    \n",
    "    coef_est = rfit.summary2().tables[1]['Coef.']['dtil']\n",
    "    se = rfit.summary2().tables[1]['Std.Err.']['dtil']\n",
    "\n",
    "    print(\"Coefficient is {}, SE is equal to {}\".format(coef_est, se))\n",
    "    \n",
    "    return coef_est, se, dtil, ytil, rfit\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2bb6fecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create main variables\n",
    "Y = rdata['logghomr']\n",
    "D = rdata['logfssl']\n",
    "Z = rdata.drop(['logghomr', 'logfssl', 'CountyCode'], axis=1)\n",
    "CLU = rdata['CountyCode']\n",
    "\n",
    "# as matrix\n",
    "y = Y.to_numpy().reshape( len(Y) , 1 )\n",
    "d = D.to_numpy().reshape( len(Y) , 1 )\n",
    "z = Z.to_numpy()\n",
    "clu = CLU.to_numpy().reshape( len(Y) , 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4f024eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  \n",
      "1  \n",
      "Coefficient is 0.230760284445633, SE is equal to 0.09054080195401883\n"
     ]
    }
   ],
   "source": [
    "DML2_nn = DML2_for_NN(z, d, y, 2, clu, 100, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f21a172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_15 (Dense)             (None, 16)                3184      \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 3,473\n",
      "Trainable params: 3,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# # define the keras model\n",
    "# model = Sequential()\n",
    "# model.add(Dense(16, input_dim = rdata.shape[1], activation = 'relu'))\n",
    "# model.add(Dense(16, activation = 'relu'))\n",
    "# model.add(Dense(1))\n",
    "# # compile the keras model\n",
    "# opt = keras.optimizers.RMSprop()\n",
    "# mse = tf.keras.losses.MeanSquaredError()\n",
    "# mae = tf.keras.metrics.MeanAbsoluteError(name=\"mean_absolute_error\", dtype=None)\n",
    "# model.compile(loss=mse, optimizer= opt , metrics=mae)\n",
    "\n",
    "# # fit the keras model on the dataset\n",
    "# num_epochs = 10\n",
    "# batch_size = 10\n",
    "\n",
    "# # fit the keras model on the dataset\n",
    "# model_D = model.fit(model_X_basic_train, Y_train, epochs=num_epochs, batch_size=batch_size, verbose = 0)\n",
    "# model_Y = model.fit(model_X_basic_train, Y_train, epochs=num_epochs, batch_size=batch_size, verbose = 0)\n",
    "\n",
    "# # predict values \n",
    "# dhat = model_D.predict(model_X_basic_test)\n",
    "# yhat = model_Y.predict(model_X_basic_test)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
